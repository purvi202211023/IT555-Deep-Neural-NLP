{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purvi202211023/IT555-Deep-Neural-NLP/blob/Train-Word2Vec-on-peS2o-Dataset-(AllenNLP)-_Assignment1/Deep_Neural_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import inflect\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from num2words import num2words  # For numerical-to-text conversion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT5YvJirBr49",
        "outputId": "4a21f9f5-c6b3-49ca-fe72-d2a2048319bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (0.5.12)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrc-ekuiBudf",
        "outputId": "c4fcfeec-7e34-49b3-d2df-e85960228f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTVXbrn5BN1b",
        "outputId": "d6b6d798-a241-4a38-dc1c-1e5c185d030d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLCdcQLd9kat"
      },
      "outputs": [],
      "source": [
        "# # Load the training data\n",
        "# df_train_n = pd.read_pickle(\"/content/drive/MyDrive/NLP/train_data_n.pkl\")\n",
        "\n",
        "# # Load the test data\n",
        "# df_test_n = pd.read_pickle(\"/content/drive/MyDrive/NLP/test_data_n.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(\"/content/drive/MyDrive/df_new.pkl\")\n",
        "df_train = df[:3000]\n",
        "df_test = df[3000:4000]"
      ],
      "metadata": {
        "id": "DgdyvL5KE-tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rwx0Yqt4KbxC",
        "outputId": "d58ff6ee-f6bc-48ea-f17d-0ad8f485abbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id      source version                     added  \\\n",
              "0      79374620  s2ag/train      v1  2019-03-16T13:05:58.356Z   \n",
              "1      53596570  s2ag/train      v1  2018-11-07T20:43:16.101Z   \n",
              "2      60680010  s2ag/train      v1  2019-02-13T14:02:18.109Z   \n",
              "3     254100620  s2ag/train      v1  2022-12-01T14:30:17.430Z   \n",
              "4      17912070  s2ag/train      v1  2014-10-01T00:00:00.000Z   \n",
              "...         ...         ...     ...                       ...   \n",
              "2995   69728870  s2ag/train      v1  2019-02-19T14:07:21.453Z   \n",
              "2996   63439480  s2ag/train      v1  2019-02-16T14:28:03.063Z   \n",
              "2997  251327930  s2ag/train      v1  2022-08-05T10:28:00.914Z   \n",
              "2998   10970270  s2ag/train      v1  2017-02-17T00:19:40.761Z   \n",
              "2999   28456170  s2ag/train      v1  2017-02-14T01:52:18.745Z   \n",
              "\n",
              "                       created  \\\n",
              "0     2006-01-01T00:00:00.000Z   \n",
              "1     2003-09-24T00:00:00.000Z   \n",
              "2     2004-01-01T00:00:00.000Z   \n",
              "3     2022-10-10T00:00:00.000Z   \n",
              "4     2001-01-01T00:00:00.000Z   \n",
              "...                        ...   \n",
              "2995  2018-06-25T00:00:00.000Z   \n",
              "2996  2009-08-31T00:00:00.000Z   \n",
              "2997  2020-01-01T00:00:00.000Z   \n",
              "2998  2015-09-02T00:00:00.000Z   \n",
              "2999  2011-06-08T00:00:00.000Z   \n",
              "\n",
              "                                                   text  \n",
              "0     In-time rating of continuously cast semis by m...  \n",
              "1     Development of an Inspection System for Cracks...  \n",
              "2     Assessment of Wave-Induced Liquefaction in a P...  \n",
              "3     Prediction of Cascading Failures and Simultane...  \n",
              "4     2 3 Ju l 2 00 1 A Logical Framework for Conver...  \n",
              "...                                                 ...  \n",
              "2995  Learning Experience Technology Usability Desig...  \n",
              "2996  Data Mining in Biomedicine Using Ontologies\\n\\...  \n",
              "2997  The Situation and Development Route of Greenho...  \n",
              "2998  Collaborative Composition of Production Servic...  \n",
              "2999  The design of voice recognition controller via...  \n",
              "\n",
              "[3000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21a6cdc9-0482-4354-8c9a-d3ee9d21b6cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>source</th>\n",
              "      <th>version</th>\n",
              "      <th>added</th>\n",
              "      <th>created</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79374620</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2019-03-16T13:05:58.356Z</td>\n",
              "      <td>2006-01-01T00:00:00.000Z</td>\n",
              "      <td>In-time rating of continuously cast semis by m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53596570</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2018-11-07T20:43:16.101Z</td>\n",
              "      <td>2003-09-24T00:00:00.000Z</td>\n",
              "      <td>Development of an Inspection System for Cracks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60680010</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2019-02-13T14:02:18.109Z</td>\n",
              "      <td>2004-01-01T00:00:00.000Z</td>\n",
              "      <td>Assessment of Wave-Induced Liquefaction in a P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>254100620</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2022-12-01T14:30:17.430Z</td>\n",
              "      <td>2022-10-10T00:00:00.000Z</td>\n",
              "      <td>Prediction of Cascading Failures and Simultane...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17912070</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2014-10-01T00:00:00.000Z</td>\n",
              "      <td>2001-01-01T00:00:00.000Z</td>\n",
              "      <td>2 3 Ju l 2 00 1 A Logical Framework for Conver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>69728870</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2019-02-19T14:07:21.453Z</td>\n",
              "      <td>2018-06-25T00:00:00.000Z</td>\n",
              "      <td>Learning Experience Technology Usability Desig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>63439480</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2019-02-16T14:28:03.063Z</td>\n",
              "      <td>2009-08-31T00:00:00.000Z</td>\n",
              "      <td>Data Mining in Biomedicine Using Ontologies\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>251327930</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2022-08-05T10:28:00.914Z</td>\n",
              "      <td>2020-01-01T00:00:00.000Z</td>\n",
              "      <td>The Situation and Development Route of Greenho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>10970270</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2017-02-17T00:19:40.761Z</td>\n",
              "      <td>2015-09-02T00:00:00.000Z</td>\n",
              "      <td>Collaborative Composition of Production Servic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>28456170</td>\n",
              "      <td>s2ag/train</td>\n",
              "      <td>v1</td>\n",
              "      <td>2017-02-14T01:52:18.745Z</td>\n",
              "      <td>2011-06-08T00:00:00.000Z</td>\n",
              "      <td>The design of voice recognition controller via...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21a6cdc9-0482-4354-8c9a-d3ee9d21b6cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21a6cdc9-0482-4354-8c9a-d3ee9d21b6cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21a6cdc9-0482-4354-8c9a-d3ee9d21b6cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f80610a-5753-4a42-9346-43e8318de517\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f80610a-5753-4a42-9346-43e8318de517')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f80610a-5753-4a42-9346-43e8318de517 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an inflect engine for number-to-text conversion\n",
        "p = inflect.engine()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove bullets\n",
        "    text = re.sub(r'\\u2022', '', text)\n",
        "\n",
        "    # Handle apostrophe\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "\n",
        "    # Handle hyphens\n",
        "    text = text.replace(\"-\", \" \")\n",
        "    text = text.replace(\"_\", \" \")\n",
        "\n",
        "    # Handle enumerations\n",
        "    text = re.sub(r'\\(i\\)|\\(ii\\)|\\(iii\\)|\\(iv\\)|\\(v\\)|\\(vi\\)|\\(vii\\)|\\(viii\\)|\\(ix\\)|\\(x\\)', '', text)\n",
        "\n",
        "    # Convert numbers to text\n",
        "    text = ' '.join([p.number_to_words(word) if bool(re.search(r'\\d', word)) else word for word in text.split()])\n",
        "\n",
        "    # Remove punctuations\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Tokenize and remove stopwords\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Tokenize the text in df_train into sentences\n",
        "sentences_train = [sent_tokenize(text) for text in df_train['text']]\n",
        "sentences_train = [sentence for sublist in sentences_train for sentence in sublist]  # Flatten the list\n",
        "\n",
        "# Apply the pre-processing function to each sentence\n",
        "processed_sentences = [preprocess_text(sentence) for sentence in sentences_train]\n",
        "\n",
        "processed_sentences[:5]  # Display first 5 processed sentences\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EyLAiVdCzMt",
        "outputId": "ad5b94f5-2d78-4f15-d533-d13381aaa6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['time rating continuously cast semis means hybrid quality models efficient reliable time determination surface internal quality continuous cast products deliver considerable contribution cost reduction efficiency improvement steel plants',\n",
              " 'currently economic losses environmental impacts caused downgrading slabs billets additionally due conditioning increased material energy consumption occur',\n",
              " 'nowadays development quality prediction models supported availability automatic inspection systems eg',\n",
              " 'surface inspection hot cold rolled strips bars',\n",
              " 'developing validating quality model concerning defects occur downstream process steps casting information inspection system reliable human decisions model adjusted accuracy']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_for_numbers(processed_sentences):\n",
        "    sentences_with_numbers = [sentence for sentence in processed_sentences if bool(re.search(r'\\d', sentence))]\n",
        "    return sentences_with_numbers\n",
        "\n",
        "# Using the function\n",
        "sentences_with_numbers = check_for_numbers(processed_sentences)\n",
        "\n",
        "if sentences_with_numbers:\n",
        "    print(f\"Found {len(sentences_with_numbers)} sentences with numbers:\")\n",
        "    for sent in sentences_with_numbers:\n",
        "        print(sent)\n",
        "else:\n",
        "    print(\"No numbers found in the processed sentences!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRh7Yi3J45zS",
        "outputId": "4db82489-507b-4c7a-e454-44f7c9a48a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No numbers found in the processed sentences!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(processed_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ-06b0WD_Pm",
        "outputId": "d2066bca-bffb-4bc3-9fb4-ee1a6a9230c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24432"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Function to apply all preprocessing steps\n",
        "# def preprocess_text(text):\n",
        "#     # Convert text to lowercase\n",
        "#     text = text.lower()\n",
        "\n",
        "#     # Remove URLs\n",
        "#     text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "#     # Remove bullets and enumerations\n",
        "#     text = re.sub(r'•|\\d+\\.', '', text)\n",
        "\n",
        "#     # Remove apostrophes\n",
        "#     text = re.sub(r\"([’'‘’])\", '', text)\n",
        "\n",
        "#     # Remove hyphens\n",
        "#     text = re.sub(r\"-\", ' ', text)\n",
        "\n",
        "#     # Convert numerical digits to text\n",
        "#     text = ' '.join([num2words(word) if word.isdigit() else word for word in text.split()])\n",
        "\n",
        "#     # Tokenize the text\n",
        "#     tokens = word_tokenize(text)\n",
        "\n",
        "#     # Remove stopwords\n",
        "#     stop_words = set(stopwords.words('english'))\n",
        "#     tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "#     # Remove punctuation\n",
        "#     tokens = [word for word in tokens if word.isalnum()]\n",
        "\n",
        "#     # Join tokens back into a single string\n",
        "#     text = ' '.join(tokens)\n",
        "\n",
        "#     return text\n",
        "\n",
        "# # Apply the preprocessing function to the \"text\" column\n",
        "# combined_df['text'] = combined_df['text'].apply(preprocess_text)\n",
        "\n",
        "# # Print the preprocessed DataFrame\n",
        "# print(combined_df)"
      ],
      "metadata": {
        "id": "8ckDc0VGG9iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the training data and transform it to create the context matrix\n",
        "context_matrix_train = tfidf_vectorizer.fit_transform(processed_sentences)\n"
      ],
      "metadata": {
        "id": "Xix9HYAwI1Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "Do9PSYczKuTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the TF-IDF context matrix to a DataFrame for easier viewing\n",
        "context_matrix_train_df = pd.DataFrame(context_matrix_train.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display the DataFrame\n",
        "print(context_matrix_train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "126We2PUKj6y",
        "outputId": "cc7367cd-a549-4e16-d309-17b2b3a58245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       aaai  aacc  aace  aachen  aacr  aade  aalto  aamas  aaohns  aarhus  \\\n",
            "0       0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "1       0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "2       0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "3       0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "4       0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "...     ...   ...   ...     ...   ...   ...    ...    ...     ...     ...   \n",
            "24427   0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "24428   0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "24429   0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "24430   0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "24431   0.0   0.0   0.0     0.0   0.0   0.0    0.0    0.0     0.0     0.0   \n",
            "\n",
            "       ...   이차  키워드   탐색  프로파일  프로파일의  ﬁeld  ﬁelds  ﬁnal  ﬁve  ﬂight  \n",
            "0      ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "1      ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "2      ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "3      ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "4      ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "...    ...  ...  ...  ...   ...    ...   ...    ...   ...  ...    ...  \n",
            "24427  ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "24428  ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "24429  ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "24430  ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "24431  ...  0.0  0.0  0.0   0.0    0.0   0.0    0.0   0.0  0.0    0.0  \n",
            "\n",
            "[24432 rows x 26031 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiply matrix with hot vector"
      ],
      "metadata": {
        "id": "msaTL6qLgwCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# # Tokenize the sentences in your preprocessed training data\n",
        "tokenized_sentences = [sentence.split() for sentence in processed_sentences]\n",
        "\n",
        "# # Set Word2Vec hyperparameters\n",
        "# vector_size = 100  # Adjust the vector size as needed\n",
        "# window = 5  # Adjust the context window size as needed\n",
        "# min_count = 1  # Minimum word count, adjust as needed\n",
        "# sg = 0  # Use CBOW (Continuous Bag of Words) model, set to 1 for Skip-gram\n",
        "\n",
        "# # Initialize and train the Word2Vec model\n",
        "# word2vec_model = Word2Vec(tokenized_sentences, vector_size=vector_size, window=window, min_count=min_count, sg=sg)\n"
      ],
      "metadata": {
        "id": "nVZYUUDLX-PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "model.train(tokenized_sentences, total_examples=len(tokenized_sentences), epochs=100)"
      ],
      "metadata": {
        "id": "5EuCOTdVBjSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882cf590-241c-4aa7-ca19-a741b84f2f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37882357, 39367400)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tfidf_weighted_word2vec_optimized(tfidf_matrix, tfidf_feature_names, w2v_model):\n",
        "    # Precompute word embeddings for all the vocabulary words\n",
        "    word_embeddings = {word: w2v_model.wv[word] for word in tfidf_feature_names if word in w2v_model.wv}\n",
        "\n",
        "    # Convert word embeddings to a matrix form\n",
        "    embedding_matrix = np.zeros((len(tfidf_feature_names), w2v_model.vector_size))\n",
        "    for i, word in enumerate(tfidf_feature_names):\n",
        "        if word in word_embeddings:\n",
        "            embedding_matrix[i] = word_embeddings[word]\n",
        "\n",
        "    # Use matrix multiplication to get the document embeddings\n",
        "    doc_embeddings = tfidf_matrix.dot(embedding_matrix)\n",
        "\n",
        "    return doc_embeddings"
      ],
      "metadata": {
        "id": "yFvH6_Tl5rmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_embeddings = tfidf_weighted_word2vec_optimized(context_matrix_train, tfidf_feature_names, model)\n",
        "print(doc_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvBRN8mH5vX2",
        "outputId": "3c9687b6-e176-44d0-a0b7-7741f825e690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.4678576   2.78063561  1.07777167 ...  0.43808938  0.88900405\n",
            "   3.71124423]\n",
            " [ 0.46219418  3.00381085  3.25360596 ... -0.30098841 -1.93462738\n",
            "   1.83743916]\n",
            " [ 1.71205679 -0.89931819 -3.04423984 ... -1.33029437  0.85944849\n",
            "   0.53314669]\n",
            " ...\n",
            " [ 0.52439886 -1.04842381 -0.60738323 ... -1.64926373 -1.47665975\n",
            "  -1.02158715]\n",
            " [ 0.32080643  4.14160527  0.14475278 ...  0.03515094  0.14039905\n",
            "  -0.42089222]\n",
            " [-1.9811232  -0.02916519 -4.57580832 ... -2.39396451 -1.54370425\n",
            "   2.28455439]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text in df_train into sentences\n",
        "sentences_test = [sent_tokenize(text) for text in df_test['text']]\n",
        "sentences_test = [sentence for sublist in sentences_test for sentence in sublist]  # Flatten the list\n",
        "\n",
        "# Apply the pre-processing function to each sentence\n",
        "processed_sentences_test = [preprocess_text(sentence) for sentence in sentences_test]\n",
        "\n",
        "processed_sentences_test[:5]  # Display first 5 processed sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si8R5T125LuC",
        "outputId": "50d4382d-dd0f-4f69-e8e5-841a70e6195e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['simulated annealing metaheuristic solve optimal power flow optimal power flow problem widely studied order improve power systems operation planning',\n",
              " 'real power systems problem formulated non linear large combinatorial problem',\n",
              " 'first approaches used solve problem based mathematical methods required huge computational efforts',\n",
              " 'lately artificial intelligence techniques metaheuristics based biological processes adopted',\n",
              " 'metaheuristics require lower computational resources clear advantage addressing problem large power systems']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict_output_word(['Computer', 'science', 'information', 'technology']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxPREMZA3tEq",
        "outputId": "3109b0e7-4e05-4045-e00b-6382f11d5b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('computer', 0.9996924), ('department', 1.7939261e-05), ('engineering', 1.1264711e-05), ('technology', 8.486653e-06), ('communication', 6.089703e-06), ('communications', 5.221026e-06), ('information', 3.8731996e-06), ('age', 3.7926332e-06), ('universiti', 3.3899782e-06), ('educators', 2.6036362e-06)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict_output_word(['What', 'is', 'Computer', 'science']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-tvX6MLMjcf",
        "outputId": "8b5cf4d0-ab10-460e-9bf4-555b6a89c43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('computer', 1.0), ('mathematics', 4.325865e-13), ('stem', 2.2076714e-14), ('cognitive', 2.196654e-14), ('department', 1.11988445e-14), ('engineering', 1.0948807e-14), ('plasma', 2.4605852e-15), ('instruction', 1.2121784e-15), ('optometric', 6.3025683e-16), ('section', 6.2991013e-16)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the predictions for each test sentence\n",
        "test_predictions = []\n",
        "\n",
        "# Iterate through each test sentence\n",
        "for test_sentence in processed_sentences_test:\n",
        "    # Filter out words that are not in the model's vocabulary\n",
        "    test_sentence_in_vocab = [word for word in test_sentence if word in model.wv]\n",
        "\n",
        "    # Check if there are any words left in the test sentence after filtering\n",
        "    if test_sentence_in_vocab:\n",
        "        # Use the model to predict the most similar sentences to the test sentence\n",
        "        similar_sentences = model.wv.most_similar(positive=test_sentence_in_vocab, topn=5)\n",
        "        test_predictions.append(similar_sentences)\n",
        "    else:\n",
        "        # If the test sentence is empty after filtering, append an empty list to test_predictions\n",
        "        test_predictions.append([])\n",
        "\n",
        "# Display the predictions for the first test sentence\n",
        "print(\"Predictions for the first test sentence:\")\n",
        "print(processed_sentences_test[0])\n",
        "for prediction in test_predictions[0]:\n",
        "    print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzMGjNMh63lm",
        "outputId": "525d8b8c-1213-4d95-e852-95d155514574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for the first test sentence:\n",
            "simulated annealing metaheuristic solve optimal power flow optimal power flow problem widely studied order improve power systems operation planning\n",
            "('joanna', 0.7350724339485168)\n",
            "('rien', 0.7318426370620728)\n",
            "('ommunity', 0.7275989055633545)\n",
            "('trouillot', 0.7237244844436646)\n",
            "('leong', 0.7222837805747986)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create TF-IDF-weighted Word2Vec representations\n",
        "# def tfidf_weighted_word2vec(tfidf_matrix, tfidf_feature_names, w2v_model):\n",
        "#     doc_embeddings = []\n",
        "\n",
        "#     for doc_tfidf in tfidf_matrix:\n",
        "#         doc_embedding = np.zeros(w2v_model.vector_size)\n",
        "#         for word, weight in zip(tfidf_feature_names, doc_tfidf.toarray()[0]):\n",
        "#             if word in w2v_model.wv:\n",
        "#                 doc_embedding += weight * w2v_model.wv[word]\n",
        "#         doc_embeddings.append(doc_embedding)\n",
        "\n",
        "#     return np.array(doc_embeddings)\n",
        "\n",
        "# doc_embeddings = tfidf_weighted_word2vec(context_matrix_train, tfidf_feature_names, model)\n",
        "# print(doc_embeddings)"
      ],
      "metadata": {
        "id": "uGqSghkML92Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}